{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4be8024d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3aca70ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/essays.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "df0e50a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           #AUTHID                                               TEXT cEXT  \\\n",
       "0  1997_504851.txt  Well, right now I just woke up from a mid-day ...    n   \n",
       "1  1997_605191.txt  Well, here we go with the stream of consciousn...    n   \n",
       "2  1997_687252.txt  An open keyboard and buttons to push. The thin...    n   \n",
       "3  1997_568848.txt  I can't believe it!  It's really happening!  M...    y   \n",
       "4  1997_688160.txt  Well, here I go with the good old stream of co...    y   \n",
       "\n",
       "  cNEU cAGR cCON cOPN  \n",
       "0    y    y    n    y  \n",
       "1    n    y    n    n  \n",
       "2    y    n    y    y  \n",
       "3    n    y    y    n  \n",
       "4    n    y    n    y  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "733be1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'y': 1, 'n': 0}\n",
    "\n",
    "df[['cEXT','cNEU','cAGR','cCON','cOPN']] = df[['cEXT','cNEU','cAGR','cCON','cOPN']].replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0bc2c9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           #AUTHID                                               TEXT  cEXT  \\\n",
       "0  1997_504851.txt  Well, right now I just woke up from a mid-day ...     0   \n",
       "1  1997_605191.txt  Well, here we go with the stream of consciousn...     0   \n",
       "2  1997_687252.txt  An open keyboard and buttons to push. The thin...     0   \n",
       "3  1997_568848.txt  I can't believe it!  It's really happening!  M...     1   \n",
       "4  1997_688160.txt  Well, here I go with the good old stream of co...     1   \n",
       "\n",
       "   cNEU  cAGR  cCON  cOPN  \n",
       "0     1     1     0     1  \n",
       "1     0     1     0     0  \n",
       "2     1     0     1     1  \n",
       "3     0     1     1     0  \n",
       "4     0     1     0     1  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "497419c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en\n",
    "\n",
    "import spacy\n",
    "import string\n",
    "import re\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "37958734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    no_punct = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    return no_punct\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return re.sub('[0-9]+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d362f9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>well, right now i just woke up from a mid-day ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>well, here we go with the stream of consciousn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>an open keyboard and buttons to push. the thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>i can't believe it!  it's really happening!  m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>well, here i go with the good old stream of co...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           #AUTHID                                               TEXT  cEXT  \\\n",
       "0  1997_504851.txt  well, right now i just woke up from a mid-day ...     0   \n",
       "1  1997_605191.txt  well, here we go with the stream of consciousn...     0   \n",
       "2  1997_687252.txt  an open keyboard and buttons to push. the thin...     0   \n",
       "3  1997_568848.txt  i can't believe it!  it's really happening!  m...     1   \n",
       "4  1997_688160.txt  well, here i go with the good old stream of co...     1   \n",
       "\n",
       "   cNEU  cAGR  cCON  cOPN  \n",
       "0     1     1     0     1  \n",
       "1     0     1     0     0  \n",
       "2     1     0     1     1  \n",
       "3     0     1     1     0  \n",
       "4     0     1     0     1  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TEXT'] = df['TEXT'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5ceb6a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>well right now i just woke up from a midday na...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>well here we go with the stream of consciousne...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>an open keyboard and buttons to push the thing...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>i cant believe it  its really happening  my pu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>well here i go with the good old stream of con...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           #AUTHID                                               TEXT  cEXT  \\\n",
       "0  1997_504851.txt  well right now i just woke up from a midday na...     0   \n",
       "1  1997_605191.txt  well here we go with the stream of consciousne...     0   \n",
       "2  1997_687252.txt  an open keyboard and buttons to push the thing...     0   \n",
       "3  1997_568848.txt  i cant believe it  its really happening  my pu...     1   \n",
       "4  1997_688160.txt  well here i go with the good old stream of con...     1   \n",
       "\n",
       "   cNEU  cAGR  cCON  cOPN  \n",
       "0     1     1     0     1  \n",
       "1     0     1     0     0  \n",
       "2     1     0     1     1  \n",
       "3     0     1     1     0  \n",
       "4     0     1     0     1  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TEXT'] = df['TEXT'].apply(remove_punctuation)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b4ee1d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>well right now i just woke up from a midday na...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>well here we go with the stream of consciousne...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>an open keyboard and buttons to push the thing...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>i cant believe it  its really happening  my pu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>well here i go with the good old stream of con...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           #AUTHID                                               TEXT  cEXT  \\\n",
       "0  1997_504851.txt  well right now i just woke up from a midday na...     0   \n",
       "1  1997_605191.txt  well here we go with the stream of consciousne...     0   \n",
       "2  1997_687252.txt  an open keyboard and buttons to push the thing...     0   \n",
       "3  1997_568848.txt  i cant believe it  its really happening  my pu...     1   \n",
       "4  1997_688160.txt  well here i go with the good old stream of con...     1   \n",
       "\n",
       "   cNEU  cAGR  cCON  cOPN  \n",
       "0     1     1     0     1  \n",
       "1     0     1     0     0  \n",
       "2     1     0     1     1  \n",
       "3     0     1     1     0  \n",
       "4     0     1     0     1  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TEXT'] = df['TEXT'].apply(remove_numbers)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7d079235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in STOP_WORDS]\n",
    "    return filtered_tokens\n",
    "\n",
    "def lemmatizer(text):\n",
    "    document = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in document]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d49107ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['TEXT'] = df['TEXT'].apply(tokenize)\n",
    "#df.head()\n",
    "\n",
    "#df['TEXT'] = df['TEXT'].apply(lemmatizer)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b68a156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['TEXT'] = df['TEXT'].apply(remove_stopwords)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e298af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty(tokens):\n",
    "    filtered_tokens = [token for token in tokens if token != \" \"]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "cdb12de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['TEXT'] = df['TEXT'].apply(remove_empty)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c649fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(sequence, n, **kwargs):\n",
    "    ngrams = []\n",
    "    sequence_length = len(sequence)\n",
    "    for i in range(sequence_length):\n",
    "        if sequence_length >= i + n:\n",
    "            seq = (sequence[i])\n",
    "            for k in range(n-1):\n",
    "                seq = (seq, sequence[i+k+1])\n",
    "            ngrams.append(seq)\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "813eaf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    lines.pop(0)  \n",
    "    return re.sub(\"[\\t ]{2,}\", \" \", \" \".join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "05097480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_pipe(doc, max_len=100, ngram_min=1, ngram_max=2):\n",
    "    document = nlp(doc)\n",
    "    \n",
    "    lemmas = []\n",
    "    for token in document:\n",
    "        if not token.is_stop:\n",
    "            lemmas.append(token.lemma_)\n",
    "    lemmas = lemmas[:max_len]\n",
    "    len_lemmas = len(lemmas)\n",
    "\n",
    "    ngrams = []\n",
    "    for n in range(ngram_min, ngram_max + 1):\n",
    "        for i in range(len_lemmas - n + 1):\n",
    "            ngrams.append(tuple(lemmas[i:i+n]))\n",
    "\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "fadf5dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "      <th>LEMMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>well right now i just woke up from a midday na...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[(right,), (wake,), (midday,), (nap,), (sort,)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>well here we go with the stream of consciousne...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(stream,), (consciousness,), (essay,), (thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>an open keyboard and buttons to push the thing...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[(open,), (keyboard,), (button,), (push,), (th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>i cant believe it  its really happening  my pu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[(not,), (believe,), ( ,), (happen,), ( ,), (p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>well here i go with the good old stream of con...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[(good,), (old,), (stream,), (consciousness,),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           #AUTHID                                               TEXT  cEXT  \\\n",
       "0  1997_504851.txt  well right now i just woke up from a midday na...     0   \n",
       "1  1997_605191.txt  well here we go with the stream of consciousne...     0   \n",
       "2  1997_687252.txt  an open keyboard and buttons to push the thing...     0   \n",
       "3  1997_568848.txt  i cant believe it  its really happening  my pu...     1   \n",
       "4  1997_688160.txt  well here i go with the good old stream of con...     1   \n",
       "\n",
       "   cNEU  cAGR  cCON  cOPN                                              LEMMA  \n",
       "0     1     1     0     1  [(right,), (wake,), (midday,), (nap,), (sort,)...  \n",
       "1     0     1     0     0  [(stream,), (consciousness,), (essay,), (thing...  \n",
       "2     1     0     1     1  [(open,), (keyboard,), (button,), (push,), (th...  \n",
       "3     0     1     1     0  [(not,), (believe,), ( ,), (happen,), ( ,), (p...  \n",
       "4     0     1     0     1  [(good,), (old,), (stream,), (consciousness,),...  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LEMMA'] = df['TEXT'].apply(lemmatize_pipe)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "81eb95a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(\n",
    "    df[['LEMMA', 'cEXT','cNEU','cAGR','cCON','cOPN']], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "b9e756e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False, min_df=3)\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=lambda doc: doc, lowercase=False, min_df=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "6c2def0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5836999717986353"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#countvect + classifierchain + rfc\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X_train = count_vectorizer.fit_transform(df_train['LEMMA'])\n",
    "y_train = df_train[['cEXT','cNEU','cAGR','cCON','cOPN']]\n",
    "\n",
    "X_test = count_vectorizer.transform(df_test['LEMMA'])\n",
    "y_test = df_test[['cEXT','cNEU','cAGR','cCON','cOPN']]\n",
    "\n",
    "model = ClassifierChain(RandomForestClassifier())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "f1_macro = f1_score(y_test, prediction, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c0e8ca49",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'precision_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[224], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score\n\u001b[1;32m      3\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, prediction)\n\u001b[0;32m----> 4\u001b[0m precision \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_score\u001b[49m(y_test, prediction)\n\u001b[1;32m      5\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(y_test, prediction)\n\u001b[1;32m      6\u001b[0m f1_micro \u001b[38;5;241m=\u001b[39m f1_score(y_test, prediction, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'precision_score' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, prediction)\n",
    "precision = precision_score(y_test, prediction)\n",
    "recall = recall_score(y_test, prediction)\n",
    "f1_micro = f1_score(y_test, prediction, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "799641b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#countvect + classifierchain + lr\n",
    "\n",
    "X_train = count_vectorizer.fit_transform(df_train['LEMMA'])\n",
    "y_train = df_train[['cEXT','cNEU','cAGR','cCON','cOPN']]\n",
    "\n",
    "X_test = count_vectorizer.transform(df_test['LEMMA'])\n",
    "y_test = df_test[['cEXT','cNEU','cAGR','cCON','cOPN']]\n",
    "\n",
    "model = ClassifierChain(LogisticRegression())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "186cef81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5502009071245826"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test, prediction, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "60fd0204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#countvect + classifierchain + svc\n",
    "\n",
    "X_train = count_vectorizer.fit_transform(df_train['LEMMA'])\n",
    "y_train = df_train[['cEXT','cNEU','cAGR','cCON','cOPN']]\n",
    "\n",
    "X_test = count_vectorizer.transform(df_test['LEMMA'])\n",
    "y_test = df_test[['cEXT','cNEU','cAGR','cCON','cOPN']]\n",
    "\n",
    "model = ClassifierChain(SVC())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4f80b47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5916427667697961"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test, prediction, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ad319a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5778181695572828"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidfvect + classifierchain + rfc\n",
    "\n",
    "X_train2 = tfidf_vectorizer.fit_transform(df_train['LEMMA'])\n",
    "y_train2 = df_train[['cEXT','cNEU','cAGR','cCON','cOPN']]\n",
    "\n",
    "X_test2 = tfidf_vectorizer.transform(df_test['LEMMA'])\n",
    "y_test2 = df_test[['cEXT','cNEU','cAGR','cCON','cOPN']]\n",
    "\n",
    "model = ClassifierChain(RandomForestClassifier())\n",
    "model.fit(X_train2, y_train2)\n",
    "\n",
    "prediction = model.predict(X_test2)\n",
    "f1_macro = f1_score(y_test2, prediction, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "4d4f32ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5754314437772138"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidfvect + classifierchain + lr\n",
    "\n",
    "X_train2 = tfidf_vectorizer.fit_transform(df_train['LEMMA'])\n",
    "y_train2 = df_train[['cEXT','cNEU','cAGR','cCON','cOPN']]\n",
    "\n",
    "X_test2 = tfidf_vectorizer.transform(df_test['LEMMA'])\n",
    "y_test2 = df_test[['cEXT','cNEU','cAGR','cCON','cOPN']]\n",
    "\n",
    "model = ClassifierChain(LogisticRegression())\n",
    "model.fit(X_train2, y_train2)\n",
    "\n",
    "prediction = model.predict(X_test2)\n",
    "f1_macro = f1_score(y_test2, prediction, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d70386e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5634240984669608"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidfvect + classifierchain + svc\n",
    "\n",
    "X_train2 = tfidf_vectorizer.fit_transform(df_train['LEMMA'])\n",
    "y_train2 = df_train[['cEXT','cNEU','cAGR','cCON','cOPN']]\n",
    "\n",
    "X_test2 = tfidf_vectorizer.transform(df_test['LEMMA'])\n",
    "y_test2 = df_test[['cEXT','cNEU','cAGR','cCON','cOPN']]\n",
    "\n",
    "model = ClassifierChain(SVC())\n",
    "model.fit(X_train2, y_train2)\n",
    "\n",
    "prediction = model.predict(X_test2)\n",
    "f1_macro = f1_score(y_test2, prediction, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "80e4adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ovr + rfc\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import numpy as np\n",
    "\n",
    "models = [OneVsRestClassifier(SVC()) for _ in range(5)]\n",
    "i = 0\n",
    "for j in ['cEXT','cNEU','cAGR','cCON','cOPN']:\n",
    "    models[i].fit(X_train, y_train[j])\n",
    "    i = i + 1\n",
    "\n",
    "predictions = [model.predict(X_test) for model in models]\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "predictions = predictions.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "0c932a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5949874765360368"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test, predictions, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "8a599988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4964913531674293"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test['cEXT'], predictions2[0], average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "fc3374af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.540438750712058"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test['cNEU'], predictions2[1], average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "d3cf4e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5323956121726823"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test['cAGR'], predictions2[2], average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2bfbc75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5377037876175934"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test['cCON'], predictions2[3], average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a08a026c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5826791446715045"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test['cOPN'], predictions2[4], average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "8dadaaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#ovr + lr\n",
    "\n",
    "models = [OneVsRestClassifier(LogisticRegression()) for _ in range(5)]\n",
    "i = 0\n",
    "for j in ['cEXT','cNEU','cAGR','cCON','cOPN']:\n",
    "    models[i].fit(X_train, y_train[j])\n",
    "    i = i + 1\n",
    "\n",
    "predictions = [model.predict(X_test) for model in models]\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "predictions = predictions.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "973223cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5529538386713592"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test, predictions, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "a79751a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4964913531674293"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test['cEXT'], predictions2[0], average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9ce9fc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.540438750712058"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test['cNEU'], predictions2[1], average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c8d33b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5323956121726823"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test['cAGR'], predictions2[2], average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7bba8c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5377037876175934"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test['cCON'], predictions2[3], average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "19a88edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5826791446715045"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test['cOPN'], predictions2[4], average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "38e08e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ovr + svc\n",
    "\n",
    "models = [OneVsRestClassifier(RandomForestClassifier()) for _ in range(5)]\n",
    "i = 0\n",
    "for j in ['cEXT','cNEU','cAGR','cCON','cOPN']:\n",
    "    models[i].fit(X_train, y_train[j])\n",
    "    i = i + 1\n",
    "\n",
    "predictions = [model.predict(X_test) for model in models]\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "predictions = predictions.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "51a698f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5924001424528655"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test, predictions, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "ea64793c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5178105376046785"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1_macro = f1_score(y_test['cEXT'], predictions[0], average='macro')\n",
    "predictions2 = np.array(predictions)\n",
    "predictions2 = predictions2.T\n",
    "\n",
    "f1_macro = f1_score(y_test['cEXT'], predictions2[0], average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "09467f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5439943876232323"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test['cNEU'], predictions2[1], average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "db1feac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5181342555644232"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test['cAGR'], predictions2[2], average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "df7c5f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5760039752450647"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test['cCON'], predictions2[3], average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2a2312b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5711858479893037"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test['cOPN'], predictions2[4], average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "482770f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5928455628300527"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf + moc + rfc\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['TEXT'], df[['cEXT', 'cNEU', 'cAGR', 'cCON', 'cOPN']], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "classifier = MultiOutputClassifier(RandomForestClassifier())\n",
    "\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "bd0886ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5898811313585257"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#countvect + moc + rfc\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "classifier = MultiOutputClassifier(RandomForestClassifier())\n",
    "\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "0b1601aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6002012426460321"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf + moc + lr\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "classifier = MultiOutputClassifier(LogisticRegression())\n",
    "\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "d1b02b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5607392780124458"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#countvect + moc + lr\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "classifier = MultiOutputClassifier(LogisticRegression())\n",
    "\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "86acbaed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5954924930854043"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf + moc + svc\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "classifier = MultiOutputClassifier(SVC())\n",
    "\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "995ffd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5672934559857881"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#countvect + moc + svc\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "classifier = MultiOutputClassifier(SVC())\n",
    "\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "2feeb2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6114914971860461"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is to check how labels are correlated !!!\n",
    "\n",
    "# highly correlated - \n",
    "X_train, X_test, y_train, y_test = train_test_split(df['TEXT'], df[['cNEU', 'cAGR']], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "classifier = MultiOutputClassifier(LogisticRegression())\n",
    "\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "6fa168b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6155704352474896"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is to check how labels are correlated !!!\n",
    "\n",
    "# less correlated - \n",
    "X_train, X_test, y_train, y_test = train_test_split(df['TEXT'], df[['cOPN', 'cAGR']], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "classifier = MultiOutputClassifier(LogisticRegression())\n",
    "\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f1e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, TFGPT2Model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "gpt_model = TFGPT2Model.from_pretrained('gpt2')\n",
    "\n",
    "input_ids = []\n",
    "for text in df_train['LEMMA']:\n",
    "    encoded = tokenizer.encode(text, truncation=True, max_length=200, padding='max_length')\n",
    "    input_ids.append(encoded)\n",
    "input_ids = tf.constant(input_ids)\n",
    "\n",
    "input_layer = Input(shape=(200,), dtype=tf.int32)\n",
    "gpt_output = gpt_model(input_layer)[0]\n",
    "output_layer = Dense(5, activation='sigmoid')(gpt_output[:, -1, :])\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(input_ids, df_train[['cEXT','cNEU','cAGR','cCON','cOPN']], epochs=10, batch_size=32)\n",
    "\n",
    "encoded_test = tokenizer.encode(df_test['LEMMA'], truncation=True, max_length=200, padding='max_length')\n",
    "test_input_ids = tf.constant(encoded_test)\n",
    "model.evaluate(test_input_ids, df_test[['cEXT','cNEU','cAGR','cCON','cOPN']])\n",
    "\n",
    "new_data = X_test\n",
    "encoded_new = tokenizer.encode(new_data, truncation=True, max_length=200, padding='max_length')\n",
    "new_input_ids = tf.constant(encoded_new)\n",
    "predictions = model.predict(new_input_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
