{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4be8024d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aca70ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/essays.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df0e50a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           #AUTHID                                               TEXT cEXT  \\\n",
       "0  1997_504851.txt  Well, right now I just woke up from a mid-day ...    n   \n",
       "1  1997_605191.txt  Well, here we go with the stream of consciousn...    n   \n",
       "2  1997_687252.txt  An open keyboard and buttons to push. The thin...    n   \n",
       "3  1997_568848.txt  I can't believe it!  It's really happening!  M...    y   \n",
       "4  1997_688160.txt  Well, here I go with the good old stream of co...    y   \n",
       "\n",
       "  cNEU cAGR cCON cOPN  \n",
       "0    y    y    n    y  \n",
       "1    n    y    n    n  \n",
       "2    y    n    y    y  \n",
       "3    n    y    y    n  \n",
       "4    n    y    n    y  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "733be1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'y': 1, 'n': 0}\n",
    "\n",
    "df[['cEXT','cNEU','cAGR','cCON','cOPN']] = df[['cEXT','cNEU','cAGR','cCON','cOPN']].replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bc2c9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           #AUTHID                                               TEXT  cEXT  \\\n",
       "0  1997_504851.txt  Well, right now I just woke up from a mid-day ...     0   \n",
       "1  1997_605191.txt  Well, here we go with the stream of consciousn...     0   \n",
       "2  1997_687252.txt  An open keyboard and buttons to push. The thin...     0   \n",
       "3  1997_568848.txt  I can't believe it!  It's really happening!  M...     1   \n",
       "4  1997_688160.txt  Well, here I go with the good old stream of co...     1   \n",
       "\n",
       "   cNEU  cAGR  cCON  cOPN  \n",
       "0     1     1     0     1  \n",
       "1     0     1     0     0  \n",
       "2     1     0     1     1  \n",
       "3     0     1     1     0  \n",
       "4     0     1     0     1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "497419c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en\n",
    "\n",
    "import spacy\n",
    "import string\n",
    "import re\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37958734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    no_punct = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    return no_punct\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return re.sub('[0-9]+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d362f9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>well, right now i just woke up from a mid-day ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>well, here we go with the stream of consciousn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>an open keyboard and buttons to push. the thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>i can't believe it!  it's really happening!  m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>well, here i go with the good old stream of co...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           #AUTHID                                               TEXT  cEXT  \\\n",
       "0  1997_504851.txt  well, right now i just woke up from a mid-day ...     0   \n",
       "1  1997_605191.txt  well, here we go with the stream of consciousn...     0   \n",
       "2  1997_687252.txt  an open keyboard and buttons to push. the thin...     0   \n",
       "3  1997_568848.txt  i can't believe it!  it's really happening!  m...     1   \n",
       "4  1997_688160.txt  well, here i go with the good old stream of co...     1   \n",
       "\n",
       "   cNEU  cAGR  cCON  cOPN  \n",
       "0     1     1     0     1  \n",
       "1     0     1     0     0  \n",
       "2     1     0     1     1  \n",
       "3     0     1     1     0  \n",
       "4     0     1     0     1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TEXT'] = df['TEXT'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ceb6a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>well right now i just woke up from a midday na...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>well here we go with the stream of consciousne...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>an open keyboard and buttons to push the thing...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>i cant believe it  its really happening  my pu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>well here i go with the good old stream of con...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           #AUTHID                                               TEXT  cEXT  \\\n",
       "0  1997_504851.txt  well right now i just woke up from a midday na...     0   \n",
       "1  1997_605191.txt  well here we go with the stream of consciousne...     0   \n",
       "2  1997_687252.txt  an open keyboard and buttons to push the thing...     0   \n",
       "3  1997_568848.txt  i cant believe it  its really happening  my pu...     1   \n",
       "4  1997_688160.txt  well here i go with the good old stream of con...     1   \n",
       "\n",
       "   cNEU  cAGR  cCON  cOPN  \n",
       "0     1     1     0     1  \n",
       "1     0     1     0     0  \n",
       "2     1     0     1     1  \n",
       "3     0     1     1     0  \n",
       "4     0     1     0     1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TEXT'] = df['TEXT'].apply(remove_punctuation)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4ee1d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>well right now i just woke up from a midday na...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>well here we go with the stream of consciousne...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>an open keyboard and buttons to push the thing...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>i cant believe it  its really happening  my pu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>well here i go with the good old stream of con...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           #AUTHID                                               TEXT  cEXT  \\\n",
       "0  1997_504851.txt  well right now i just woke up from a midday na...     0   \n",
       "1  1997_605191.txt  well here we go with the stream of consciousne...     0   \n",
       "2  1997_687252.txt  an open keyboard and buttons to push the thing...     0   \n",
       "3  1997_568848.txt  i cant believe it  its really happening  my pu...     1   \n",
       "4  1997_688160.txt  well here i go with the good old stream of con...     1   \n",
       "\n",
       "   cNEU  cAGR  cCON  cOPN  \n",
       "0     1     1     0     1  \n",
       "1     0     1     0     0  \n",
       "2     1     0     1     1  \n",
       "3     0     1     1     0  \n",
       "4     0     1     0     1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TEXT'] = df['TEXT'].apply(remove_numbers)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d079235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in STOP_WORDS]\n",
    "    return filtered_tokens\n",
    "\n",
    "def lemmatizer(text):\n",
    "    document = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in document]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d49107ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['TEXT'] = df['TEXT'].apply(tokenize)\n",
    "#df.head()\n",
    "\n",
    "#df['TEXT'] = df['TEXT'].apply(lemmatizer)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b68a156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['TEXT'] = df['TEXT'].apply(remove_stopwords)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e298af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty(tokens):\n",
    "    filtered_tokens = [token for token in tokens if token != \" \"]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdb12de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['TEXT'] = df['TEXT'].apply(remove_empty)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c649fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(sequence, n, **kwargs):\n",
    "    ngrams = []\n",
    "    sequence_length = len(sequence)\n",
    "    for i in range(sequence_length):\n",
    "        if sequence_length >= i + n:\n",
    "            seq = (sequence[i])\n",
    "            for k in range(n-1):\n",
    "                seq = (seq, sequence[i+k+1])\n",
    "            ngrams.append(seq)\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "813eaf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    lines.pop(0)  \n",
    "    return re.sub(\"[\\t ]{2,}\", \" \", \" \".join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05097480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_pipe(doc, max_len=100, ngram_min=1, ngram_max=2):\n",
    "    document = nlp(doc)\n",
    "    \n",
    "    lemmas = []\n",
    "    for token in document:\n",
    "        if not token.is_stop:\n",
    "            lemmas.append(token.lemma_)\n",
    "    lemmas = lemmas[:max_len]\n",
    "    len_lemmas = len(lemmas)\n",
    "\n",
    "    ngrams = []\n",
    "    for n in range(ngram_min, ngram_max + 1):\n",
    "        for i in range(len_lemmas - n + 1):\n",
    "            ngrams.append(tuple(lemmas[i:i+n]))\n",
    "\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fadf5dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "      <th>LEMMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997_504851.txt</td>\n",
       "      <td>well right now i just woke up from a midday na...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[(right,), (wake,), (midday,), (nap,), (sort,)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997_605191.txt</td>\n",
       "      <td>well here we go with the stream of consciousne...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[(stream,), (consciousness,), (essay,), (thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997_687252.txt</td>\n",
       "      <td>an open keyboard and buttons to push the thing...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[(open,), (keyboard,), (button,), (push,), (th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997_568848.txt</td>\n",
       "      <td>i cant believe it  its really happening  my pu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[(not,), (believe,), ( ,), (happen,), ( ,), (p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997_688160.txt</td>\n",
       "      <td>well here i go with the good old stream of con...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[(good,), (old,), (stream,), (consciousness,),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           #AUTHID                                               TEXT  cEXT  \\\n",
       "0  1997_504851.txt  well right now i just woke up from a midday na...     0   \n",
       "1  1997_605191.txt  well here we go with the stream of consciousne...     0   \n",
       "2  1997_687252.txt  an open keyboard and buttons to push the thing...     0   \n",
       "3  1997_568848.txt  i cant believe it  its really happening  my pu...     1   \n",
       "4  1997_688160.txt  well here i go with the good old stream of con...     1   \n",
       "\n",
       "   cNEU  cAGR  cCON  cOPN                                              LEMMA  \n",
       "0     1     1     0     1  [(right,), (wake,), (midday,), (nap,), (sort,)...  \n",
       "1     0     1     0     0  [(stream,), (consciousness,), (essay,), (thing...  \n",
       "2     1     0     1     1  [(open,), (keyboard,), (button,), (push,), (th...  \n",
       "3     0     1     1     0  [(not,), (believe,), ( ,), (happen,), ( ,), (p...  \n",
       "4     0     1     0     1  [(good,), (old,), (stream,), (consciousness,),...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LEMMA'] = df['TEXT'].apply(lemmatize_pipe)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81eb95a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(\n",
    "    df[['LEMMA', 'cEXT','cNEU','cAGR','cCON','cOPN']], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9e756e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False, min_df=3)\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=lambda doc: doc, lowercase=False, min_df=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c2def0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train = count_vectorizer.fit_transform(df_train['LEMMA'])\n",
    "y_train = df_train[['cEXT','cNEU','cAGR','cCON','cOPN']]\n",
    "\n",
    "X_test = count_vectorizer.transform(df_test['LEMMA'])\n",
    "y_test = df_test[['cEXT','cNEU','cAGR','cCON','cOPN']]\n",
    "\n",
    "model = ClassifierChain(RandomForestClassifier())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f80b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_macro = f1_score(y_test, prediction, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91a9429c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6030656959880016"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad319a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivaaamaric/opt/anaconda3/envs/iva132/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5757489105644231"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train2 = tfidf_vectorizer.fit_transform(df_train['LEMMA'])\n",
    "y_train2 = df_train[['cEXT','cNEU','cAGR','cCON','cOPN']]\n",
    "\n",
    "X_test2 = tfidf_vectorizer.transform(df_test['LEMMA'])\n",
    "y_test2 = df_test[['cEXT','cNEU','cAGR','cCON','cOPN']]\n",
    "\n",
    "model = ClassifierChain(RandomForestClassifier())\n",
    "model.fit(X_train2, y_train2)\n",
    "\n",
    "prediction = model.predict(X_test2)\n",
    "f1_macro = f1_score(y_test2, prediction, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80e4adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#LogisticRegression instead of SVC - worse f1\n",
    "models = [OneVsRestClassifier(SVC()) for _ in range(5)]\n",
    "i = 0\n",
    "for j in ['cEXT','cNEU','cAGR','cCON','cOPN']:\n",
    "    models[i].fit(X_train, y_train[j])\n",
    "    i = i + 1\n",
    "\n",
    "predictions = [model.predict(X_test) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "744a7609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494, 5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "predictions = predictions.T\n",
    "\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c932a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5949874765360368"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test, predictions, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea64793c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5027978544949987"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1_macro = f1_score(y_test['cEXT'], predictions[0], average='macro')\n",
    "predictions2 = np.array(predictions)\n",
    "predictions2 = predictions2.T\n",
    "\n",
    "f1_macro = f1_score(y_test['cEXT'], predictions2[0], average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "09467f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5686827488676192"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test['cNEU'], predictions2[1], average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db1feac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.513242862640453"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test['cAGR'], predictions2[2], average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df7c5f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5998355229342709"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test['cCON'], predictions2[3], average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a2312b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.585931532245744"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test['cOPN'], predictions2[4], average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "482770f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['TEXT'], df[['cEXT', 'cNEU', 'cAGR', 'cCON', 'cOPN']], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "classifier = MultiOutputClassifier(RandomForestClassifier())\n",
    "\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707e9a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)  # 5 labels for cEXT, cNEU, cAGR, cCON, cOPN\n",
    "\n",
    "def tokenize(text):\n",
    "    return tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "X_train_tokenized = [tokenize(text) for text in df_train['LEMMA']]\n",
    "X_test_tokenized = [tokenize(text) for text in df_test['LEMMA']]\n",
    "\n",
    "X_train_input_ids = torch.cat([x['input_ids'] for x in X_train_tokenized], dim=0)\n",
    "X_train_attention_mask = torch.cat([x['attention_mask'] for x in X_train_tokenized], dim=0)\n",
    "X_test_input_ids = torch.cat([x['input_ids'] for x in X_test_tokenized], dim=0)\n",
    "X_test_attention_mask = torch.cat([x['attention_mask'] for x in X_test_tokenized], dim=0)\n",
    "\n",
    "y_train_tensor = torch.tensor(df_train[['cEXT', 'cNEU', 'cAGR', 'cCON', 'cOPN']].values)\n",
    "y_test_tensor = torch.tensor(df_test[['cEXT', 'cNEU', 'cAGR', 'cCON', 'cOPN']].values)\n",
    "\n",
    "batch_size = 16\n",
    "num_epochs = 5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(X_train_input_ids, X_train_attention_mask, y_train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_data = torch.utils.data.TensorDataset(X_test_input_ids, X_test_attention_mask, y_test_tensor)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a716f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc8563",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        predictions = []\n",
    "        for batch in test_loader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            logits = outputs.logits\n",
    "            predictions.append(torch.sigmoid(logits))\n",
    "\n",
    "        avg_loss = total_loss / len(test_loader)\n",
    "        print(f'Test Loss: {avg_loss:.4f}')\n",
    "\n",
    "        predictions = torch.cat(predictions, dim=0).cpu().numpy()\n",
    "\n",
    "    # Compute accuracy\n",
    "    def compute_accuracy(predictions, labels):\n",
    "        predictions = (predictions > 0.5).astype(int)\n",
    "        accuracy = (predictions == labels).mean()\n",
    "        return accuracy\n",
    "\n",
    "    accuracy = compute_accuracy(predictions, y_test_tensor.numpy())\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "def predict(text):\n",
    "    model.eval()\n",
    "    tokenized = tokenize(text)\n",
    "    input_ids = tokenized['input_ids'].to(device)\n",
    "    attention_mask = tokenized['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids.unsqueeze(0), attention_mask=attention_mask.unsqueeze(0))\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.sigmoid(logits).cpu().numpy()\n",
    "    \n",
    "    return predictions[0]\n",
    "\n",
    "text = \"This is a new text to predict the personality traits.\"\n",
    "predictions = predict(text)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f1e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, TFGPT2Model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "gpt_model = TFGPT2Model.from_pretrained('gpt2')\n",
    "\n",
    "input_ids = []\n",
    "for text in df_train['LEMMA']:\n",
    "    encoded = tokenizer.encode(text, truncation=True, max_length=200, padding='max_length')\n",
    "    input_ids.append(encoded)\n",
    "input_ids = tf.constant(input_ids)\n",
    "\n",
    "input_layer = Input(shape=(200,), dtype=tf.int32)\n",
    "gpt_output = gpt_model(input_layer)[0]\n",
    "output_layer = Dense(5, activation='sigmoid')(gpt_output[:, -1, :])\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(input_ids, df_train[['cEXT','cNEU','cAGR','cCON','cOPN']], epochs=10, batch_size=32)\n",
    "\n",
    "encoded_test = tokenizer.encode(df_test['LEMMA'], truncation=True, max_length=200, padding='max_length')\n",
    "test_input_ids = tf.constant(encoded_test)\n",
    "model.evaluate(test_input_ids, df_test[['cEXT','cNEU','cAGR','cCON','cOPN']])\n",
    "\n",
    "new_data = X_test\n",
    "encoded_new = tokenizer.encode(new_data, truncation=True, max_length=200, padding='max_length')\n",
    "new_input_ids = tf.constant(encoded_new)\n",
    "predictions = model.predict(new_input_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
